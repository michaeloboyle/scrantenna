name: Enhanced Daily News with LLM Extraction

on:
  schedule:
    # Run daily at 6 AM EST (11 AM UTC)
    - cron: '0 11 * * *'
  workflow_dispatch: # Allow manual trigger

jobs:
  generate-enhanced-news:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    permissions:
      contents: write
      pages: write
      id-token: write
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-enhanced-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-enhanced-
          ${{ runner.os }}-pip-
    
    - name: Cache Ollama models
      uses: actions/cache@v4
      with:
        path: ~/.ollama
        key: ${{ runner.os }}-ollama-phi3-mini
        restore-keys: |
          ${{ runner.os }}-ollama-
    
    - name: Install Ollama
      run: |
        echo "ü¶ô Installing Ollama..."
        curl -fsSL https://ollama.com/install.sh | sh
        
        # Start Ollama service
        ollama serve &
        sleep 5
        
        # Pull lightweight Phi-3 model (smaller than Llama 3.2)
        echo "üì• Downloading Phi-3 Mini model (2.2GB)..."
        ollama pull phi3:mini
        
        # Verify installation
        ollama list
    
    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt --cache-dir ~/.cache/pip
        # Core dependencies should already be in requirements.txt
    
    - name: Generate news with LLM extraction
      env:
        NEWSAPI_KEY: ${{ secrets.NEWSAPI_KEY }}
      run: |
        echo "üì∞ Fetching daily news..."
        python src/daily_news.py
        
        echo "üß† Running enhanced entity extraction..."
        cd shorts
        python generate_shorts.py --force
        
        echo "üìä Generated $(jq '.total_shorts' shorts_data.json) shorts with LLM extraction"
    
    - name: Copy to docs for GitHub Pages
      run: |
        cp shorts/index.html docs/
        cp shorts/shorts_data.json docs/
        
        echo "üìã Deployment Summary:"
        echo "- Shorts generated: $(jq '.total_shorts' docs/shorts_data.json)"
        echo "- Method used: $(jq -r '.shorts[0].graph.method' docs/shorts_data.json)"
        echo "- Generated at: $(jq -r '.generated_at' docs/shorts_data.json)"
    
    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action Bot"
        
        git add data/daily/ docs/ static/ shorts/shorts_data.json
        
        if ! git diff --staged --quiet; then
          git commit -m "Daily news update with LLM extraction $(date '+%Y-%m-%d')
          
          üìä Generated $(jq '.total_shorts' docs/shorts_data.json) shorts
          üß† Method: $(jq -r '.shorts[0].graph.method' docs/shorts_data.json)
          
          ü§ñ Generated with [Claude Code](https://claude.ai/code)
          Co-Authored-By: Claude <noreply@anthropic.com>"
          
          git push
          echo "‚úÖ Changes committed and pushed"
        else
          echo "‚ÑπÔ∏è No changes to commit"
        fi
        
    - name: Setup Pages
      uses: actions/configure-pages@v4
    
    - name: Upload to GitHub Pages
      uses: actions/upload-pages-artifact@v3
      with:
        path: ./docs
    
    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
        
    - name: Deployment status
      run: |
        echo "üöÄ Site will be available at: http://oboyle.co/scrantenna/"
        echo "‚è±Ô∏è GitHub Pages deployment typically takes 5-10 minutes"