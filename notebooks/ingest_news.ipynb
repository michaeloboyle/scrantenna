{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest News Articles for Scrantenna\n",
    "This notebook pulls news articles from multiple sources and saves them for further processing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import requests\nimport json\nimport os\nimport re\nfrom datetime import datetime\nfrom typing import List, Dict, Tuple\n\n# Try to import OpenAI for LLM-based distillation\ntry:\n    import openai\n    llm_available = True\n    # Set up OpenAI client (will use OPENAI_API_KEY env var)\n    client = openai.OpenAI()\nexcept ImportError:\n    print(\"OpenAI not available. Install with: pip install openai\")\n    llm_available = False\n    client = None\n\n# Load SpaCy as fallback\ntry:\n    import spacy\n    nlp = spacy.load(\"en_core_web_sm\")\n    spacy_available = True\nexcept:\n    print(\"SpaCy model not found. Install with: python -m spacy download en_core_web_sm\")\n    nlp = None\n    spacy_available = False\n\n# Define constants\nAPI_KEY = 'be93936988fd4df185bd56e8a11125a0'\nQUERY = \"Scranton\"\nDATA_DIR = \"../data/daily\"\nNEWS_URL = f\"https://newsapi.org/v2/everything?q={QUERY}&apiKey={API_KEY}\"\n\ndef create_distilled_version_llm(text: str) -> str:\n    \"\"\"Create distilled version using LLM.\"\"\"\n    if not llm_available or not text:\n        return \"\"\n    \n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\n                    \"role\": \"system\", \n                    \"content\": \"Extract the core facts from news text into direct, precise statements. Use simple subject-verb-object format. Avoid referring to 'the article' or 'the story'. State facts directly as if reporting them yourself. Keep it under 100 characters.\"\n                },\n                {\n                    \"role\": \"user\", \n                    \"content\": f\"Distill this news text: {text}\"\n                }\n            ],\n            max_tokens=50,\n            temperature=0.1\n        )\n        return response.choices[0].message.content.strip()\n    except Exception as e:\n        print(f\"LLM distillation failed: {e}\")\n        return create_distilled_version_fallback(text)\n\ndef create_distilled_version_fallback(text: str) -> str:\n    \"\"\"Fallback distillation using simple text processing.\"\"\"\n    if not text:\n        return \"\"\n    \n    # Extract first sentence\n    sentences = text.split('.')\n    first_sentence = sentences[0].strip() if sentences else text\n    \n    # Remove common article references\n    first_sentence = re.sub(r'\\(.*?\\)', '', first_sentence)  # Remove parentheses\n    first_sentence = re.sub(r'^(The|A|An)\\s+', '', first_sentence)  # Remove articles\n    first_sentence = first_sentence[:80] + \".\" if len(first_sentence) > 80 else first_sentence + \".\"\n    \n    return first_sentence\n\ndef create_distilled_version(text: str) -> str:\n    \"\"\"Create distilled version using best available method.\"\"\"\n    if llm_available:\n        return create_distilled_version_llm(text)\n    else:\n        return create_distilled_version_fallback(text)\n\ndef process_article(article: Dict) -> Dict:\n    \"\"\"Process article to include distilled versions alongside original text.\"\"\"\n    processed = article.copy()\n    \n    # Use description as main content since API content is truncated\n    main_content = article.get('description', '') or article.get('title', '')\n    \n    # Add distilled versions\n    if article.get('title'):\n        processed['title_distilled'] = create_distilled_version(article['title'])\n    \n    if article.get('description'):\n        processed['description_distilled'] = create_distilled_version(article['description'])\n    \n    # Since content is truncated, use description as main content\n    processed['content_distilled'] = create_distilled_version(main_content)\n    \n    return processed\n\ndef fetch_news():\n    \"\"\"Fetch news articles from NewsAPI\"\"\"\n    response = requests.get(NEWS_URL)\n    if response.status_code != 200:\n        raise Exception(f\"Failed to fetch news articles: {response.text}\")\n    return response.json()\n\ndef save_news(news_data):\n    \"\"\"Save news articles with both original and distilled formats\"\"\"\n    if not os.path.exists(DATA_DIR):\n        os.makedirs(DATA_DIR)\n    \n    # Process articles to add distilled versions\n    processed_articles = []\n    for article in news_data.get('articles', []):\n        processed_articles.append(process_article(article))\n    \n    # Create data structure with metadata\n    output_data = {\n        \"query\": QUERY,\n        \"fetched_at\": datetime.now().isoformat(),\n        \"total_articles\": len(processed_articles),\n        \"has_distilled\": llm_available or spacy_available,\n        \"distillation_method\": \"llm\" if llm_available else \"fallback\",\n        \"articles\": processed_articles\n    }\n    \n    # Save with date-based filename\n    file_path = os.path.join(DATA_DIR, f\"scranton_news_{datetime.now().strftime('%Y-%m-%d')}.json\")\n    with open(file_path, 'w') as f:\n        json.dump(output_data, f, indent=2)\n    \n    print(f\"Saved {len(processed_articles)} articles to {file_path}\")\n    if llm_available:\n        print(\"✓ LLM-based distilled versions included\")\n    elif spacy_available:\n        print(\"✓ Fallback distilled versions included\")\n    else:\n        print(\"⚠ Distilled versions not generated\")\n    \n    return file_path\n\n# Fetch and save articles with intelligent distilled processing\nnews_data = fetch_news()\nsaved_file = save_news(news_data)"
  },
  {
   "cell_type": "code",
   "source": "# Display sample articles with toggle between original and SVO\ndef display_sample_articles(file_path, num_samples=3):\n    \"\"\"Display sample articles showing both original and SVO versions\"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"Sample Articles from {file_path}\")\n    print(f\"{'='*80}\\n\")\n    \n    for i, article in enumerate(data['articles'][:num_samples]):\n        print(f\"Article {i+1}:\")\n        print(f\"Source: {article.get('source', {}).get('name', 'Unknown')}\")\n        print(f\"\\nOriginal Title: {article.get('title', 'N/A')}\")\n        print(f\"SVO Title: {article.get('title_svo', 'N/A')}\")\n        print(f\"\\nOriginal Description: {article.get('description', 'N/A')[:150]}...\")\n        print(f\"SVO Description: {article.get('description_svo', 'N/A')}\")\n        print(f\"{'-'*80}\\n\")\n\n# Show samples from the saved file\nif 'saved_file' in locals():\n    display_sample_articles(saved_file)",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}