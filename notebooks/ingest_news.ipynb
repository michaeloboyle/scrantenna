{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest News Articles for Scrantenna\n",
    "This notebook pulls news articles from multiple sources and saves them for further processing."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import requests\nimport json\nimport os\nimport spacy\nimport re\nfrom datetime import datetime\nfrom typing import List, Dict, Tuple\n\n# Load SpaCy model\ntry:\n    nlp = spacy.load(\"en_core_web_sm\")\nexcept:\n    print(\"SpaCy model not found. Install with: python -m spacy download en_core_web_sm\")\n    nlp = None\n\n# Define constants\nAPI_KEY = 'be93936988fd4df185bd56e8a11125a0'\nQUERY = \"Scranton\"\nDATA_DIR = \"../data/daily\"\nNEWS_URL = f\"https://newsapi.org/v2/everything?q={QUERY}&apiKey={API_KEY}\"\n\ndef extract_svo_triplets(text: str) -> List[Tuple[str, str, str]]:\n    \"\"\"Extract Subject-Verb-Object triplets from text using SpaCy dependency parsing.\"\"\"\n    if not nlp or not text:\n        return []\n    \n    doc = nlp(text)\n    triplets = []\n    \n    for sent in doc.sents:\n        for token in sent:\n            if token.pos_ == \"VERB\" and token.dep_ == \"ROOT\":\n                verb = token.text\n                subject = None\n                obj = None\n                \n                for child in token.children:\n                    if child.dep_ in [\"nsubj\", \"nsubjpass\"]:\n                        subject_phrase = [child.text]\n                        for subchild in child.children:\n                            if subchild.dep_ in [\"compound\", \"amod\", \"det\"]:\n                                subject_phrase.insert(0, subchild.text)\n                        subject = \" \".join(subject_phrase)\n                    \n                    elif child.dep_ in [\"dobj\", \"pobj\", \"attr\"]:\n                        obj_phrase = [child.text]\n                        for subchild in child.children:\n                            if subchild.dep_ in [\"compound\", \"amod\", \"det\"]:\n                                obj_phrase.insert(0, subchild.text)\n                        obj = \" \".join(obj_phrase)\n                \n                if subject and verb:\n                    triplets.append((subject, verb, obj or \"[no object]\"))\n    \n    return triplets\n\ndef simplify_to_svo(text: str) -> str:\n    \"\"\"Convert text to boring, precise SVO statements.\"\"\"\n    if not text:\n        return \"\"\n    \n    triplets = extract_svo_triplets(text)\n    \n    if not triplets:\n        if nlp:\n            doc = nlp(text)\n            entities = [(ent.text, ent.label_) for ent in doc.ents]\n            if entities:\n                return f\"Article mentions {', '.join([f'{e[0]} ({e[1]})' for e in entities[:3]])}\"\n        return \"No clear statements extracted.\"\n    \n    svo_sentences = []\n    for subj, verb, obj in triplets[:5]:\n        sentence = f\"{subj.capitalize()} {verb} {obj}.\"\n        svo_sentences.append(sentence)\n    \n    return \" \".join(svo_sentences)\n\ndef process_article(article: Dict) -> Dict:\n    \"\"\"Process article to include SVO versions alongside original text.\"\"\"\n    processed = article.copy()\n    \n    # Add SVO versions if SpaCy is available\n    if nlp:\n        if article.get('title'):\n            processed['title_svo'] = simplify_to_svo(article['title'])\n        \n        if article.get('description'):\n            processed['description_svo'] = simplify_to_svo(article['description'])\n        \n        if article.get('content'):\n            clean_content = re.sub(r'\\[\\+\\d+ chars\\]', '', article['content'])\n            processed['content_svo'] = simplify_to_svo(clean_content)\n    \n    return processed\n\ndef fetch_news():\n    \"\"\"Fetch news articles from NewsAPI\"\"\"\n    response = requests.get(NEWS_URL)\n    if response.status_code != 200:\n        raise Exception(f\"Failed to fetch news articles: {response.text}\")\n    return response.json()\n\ndef save_news(news_data):\n    \"\"\"Save news articles with both original and SVO formats\"\"\"\n    if not os.path.exists(DATA_DIR):\n        os.makedirs(DATA_DIR)\n    \n    # Process articles to add SVO versions\n    processed_articles = []\n    for article in news_data.get('articles', []):\n        processed_articles.append(process_article(article))\n    \n    # Create data structure with metadata\n    output_data = {\n        \"query\": QUERY,\n        \"fetched_at\": datetime.now().isoformat(),\n        \"total_articles\": len(processed_articles),\n        \"has_svo\": nlp is not None,\n        \"articles\": processed_articles\n    }\n    \n    # Save with date-based filename\n    file_path = os.path.join(DATA_DIR, f\"scranton_news_{datetime.now().strftime('%Y-%m-%d')}.json\")\n    with open(file_path, 'w') as f:\n        json.dump(output_data, f, indent=2)\n    \n    print(f\"Saved {len(processed_articles)} articles to {file_path}\")\n    if nlp:\n        print(\"✓ SVO versions included\")\n    else:\n        print(\"⚠ SVO versions not generated (SpaCy not available)\")\n    \n    return file_path\n\n# Fetch and save articles with SVO processing\nnews_data = fetch_news()\nsaved_file = save_news(news_data)"
  },
  {
   "cell_type": "code",
   "source": "# Display sample articles with toggle between original and SVO\ndef display_sample_articles(file_path, num_samples=3):\n    \"\"\"Display sample articles showing both original and SVO versions\"\"\"\n    with open(file_path, 'r') as f:\n        data = json.load(f)\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"Sample Articles from {file_path}\")\n    print(f\"{'='*80}\\n\")\n    \n    for i, article in enumerate(data['articles'][:num_samples]):\n        print(f\"Article {i+1}:\")\n        print(f\"Source: {article.get('source', {}).get('name', 'Unknown')}\")\n        print(f\"\\nOriginal Title: {article.get('title', 'N/A')}\")\n        print(f\"SVO Title: {article.get('title_svo', 'N/A')}\")\n        print(f\"\\nOriginal Description: {article.get('description', 'N/A')[:150]}...\")\n        print(f\"SVO Description: {article.get('description_svo', 'N/A')}\")\n        print(f\"{'-'*80}\\n\")\n\n# Show samples from the saved file\nif 'saved_file' in locals():\n    display_sample_articles(saved_file)",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}